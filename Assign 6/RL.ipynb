{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import struct as st\n",
    "import numpy as np\n",
    "import keyboard\n",
    "import idx2numpy\n",
    "from PIL import Image\n",
    "from numpy import linalg as LA\n",
    "from numpy import matlib\n",
    "import sounddevice as sd\n",
    "import pickle as pkl\n",
    "import ipdb;\n",
    "from scipy.io import loadmat;\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "H=7; L=25;\n",
    "W=9; D=25;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************module for staying on sidewalk*****************\n",
    "G = np.zeros((H,L));\n",
    "Q = np.random.rand(H*L,H*L)*1e-3;\n",
    "T = np.zeros((H*L,H*L));\n",
    "H=6; L=3;\n",
    "sidewalk_penalty = 50.;\n",
    "sidewalk_reward = 5.;\n",
    "R = np.zeros((H,L))-sidewalk_penalty;\n",
    "Q = np.random.rand(H,L)*1e-3;\n",
    "#R = np.zeros((16,3))\n",
    "#R states are 000, 001, 011, 111, 110, 100; 1=on sidewalk, 0=not on sidewalk\n",
    "#actions are move NE, move E, move SE\n",
    "dict_s = {'000':0, '001':1, '011':2, '111':3, '110':4, '100':5}\n",
    "\n",
    "R[1,2] = sidewalk_reward;\n",
    "R[2,1:] = sidewalk_reward;\n",
    "R[3,:] = sidewalk_reward;\n",
    "R[4,:2] = sidewalk_reward;\n",
    "R[5,0] = sidewalk_reward;\n",
    "epsilon = 0.2;\n",
    "alpha = 0.3;\n",
    "gamma = 0.8;\n",
    "\n",
    "# ipdb.set_trace()\n",
    "\n",
    "\n",
    "deltaQ_norm = 1;\n",
    "Q_prev = Q*1.0;\n",
    "st = random.randint(0,H-1);\n",
    "iter=0;\n",
    "iter_min=500;\n",
    "iter_max=1000;\n",
    "tol=1e-3;\n",
    "M = np.random.randint(2, size=(W, D))*0\n",
    "M[3:6,:]=1;\n",
    "# st_ac_pair_picked=0;\n",
    "while iter<iter_max:\n",
    "    start = random.randint(2,6)\n",
    "    jj=0;\n",
    "    i=start;\n",
    "\n",
    "    if deltaQ_norm<tol and iter>iter_min:\n",
    "        break\n",
    "    while  jj<D-1:\n",
    "        st_int = str(M[i+1,jj+1])+ str(M[i,jj+1]) + str(M[i-1,jj+1]);\n",
    "        st = dict_s[st_int];\n",
    "        val_act_picked=0;\n",
    "        # ipdb.set_trace()\n",
    "        while val_act_picked!=1:\n",
    "            if np.random.rand()<epsilon:\n",
    "                ac = random.randint(0,L-1);\n",
    "            else:\n",
    "                ac = np.argmax(Q[st,:]);\n",
    "            if (i==W-2 and ac==0) or (i==1 and ac==2):\n",
    "                val_act_picked=0;\n",
    "            else:\n",
    "                val_act_picked=1;\n",
    "\n",
    "        if ac==0:\n",
    "            i=i+1;\n",
    "        elif ac==2:\n",
    "            i=i-1;\n",
    "        jj=jj+1;\n",
    "        # if st==5 and ac==2:\n",
    "        #     st_ac_pair_picked=1;\n",
    "        # sprime = random.randint(0,H-1);\n",
    "        if jj==D-1:\n",
    "            next_st_int = '111';\n",
    "        else:\n",
    "            next_st_int = str(M[i+1,jj+1])+ str(M[i,jj+1]) + str(M[i-1,jj+1]);\n",
    "        sprime = dict_s[next_st_int];\n",
    "        Q[st,ac] = (1-alpha)*Q[st,ac] + alpha*(R[st,ac] + gamma*max(Q[sprime,:]));\n",
    "    iter=iter+1;\n",
    "    deltaQ = np.abs(Q-Q_prev);\n",
    "    deltaQ_norm = np.mean(deltaQ);\n",
    "    # print(\"dQ = \", deltaQ_norm)\n",
    "    Q_prev = Q*1.0;\n",
    "\n",
    "Q_swalk = Q;\n",
    "\n",
    "# ipdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************module for avoiding obstacles*****************\n",
    "W=7; D=25;\n",
    "H=8; L=3;\n",
    "obstacle_penalty = -100;\n",
    "obstacle_reward = 0.;\n",
    "R = np.zeros((H,L)) + obstacle_reward;\n",
    "Q = np.random.rand(H,L)*1e-3;\n",
    "#R = np.zeros((16,3))\n",
    "#R states are 000, 001, 010, 011, 111, 110, 101, 100; 1=obstacle, 0=no obstacle\n",
    "#R actions are move NE, move E, move SE\n",
    "R[0,1] = 10.;\n",
    "R[1,2] = obstacle_penalty;\n",
    "R[2,1] = obstacle_penalty;\n",
    "R[3,1:] = obstacle_penalty;\n",
    "R[4,:] = obstacle_penalty;\n",
    "R[5,:2] = obstacle_penalty;\n",
    "R[6,[0,2]] = obstacle_penalty;\n",
    "R[7,0] = obstacle_penalty;\n",
    "epsilon = 0.1;\n",
    "alpha = 0.2;\n",
    "gamma = 0.8;\n",
    "\n",
    "# ipdb.set_trace()\n",
    "\n",
    "\n",
    "deltaQ_norm = 1;\n",
    "Q_prev = Q*1.0;\n",
    "st = random.randint(0,H-1);\n",
    "iter=0;\n",
    "tol=1e-3;\n",
    "iter_min=100;\n",
    "iter_max = 1000;\n",
    "# while deltaQ_norm>tol:\n",
    "dict_o = {'000':0, '001':1, '010':2, '011':3, '111':4, '110':5, '101':6, '100':7}\n",
    "\n",
    "while iter<iter_max:\n",
    "    start = random.randint(2,4)\n",
    "    jj=0;\n",
    "    i=start;\n",
    "    M = np.random.randint(6, size=(W, D))\n",
    "    M[M!=1]=0;\n",
    "    if deltaQ_norm<tol and iter>iter_min:\n",
    "        break\n",
    "    while jj<D-1:\n",
    "        st_int = str(M[i+1,jj+1])+ str(M[i,jj+1]) + str(M[i-1,jj+1]);\n",
    "        st = dict_o[st_int];\n",
    "        val_act_picked=0;\n",
    "        # if deltaQ_norm<tol and iter>iter_min:\n",
    "        #     break\n",
    "        # ipdb.set_trace()\n",
    "        while val_act_picked!=1:\n",
    "            if np.random.rand()<epsilon:\n",
    "                ac = random.randint(0,L-1);\n",
    "            else:\n",
    "                ac = np.argmax(Q[st,:]);\n",
    "            if (i==W-2 and ac==0) or (i==1 and ac==2):\n",
    "                val_act_picked=0;\n",
    "            else:\n",
    "                val_act_picked=1;\n",
    "\n",
    "        if ac==0:\n",
    "            i=i+1;\n",
    "        elif ac==2:\n",
    "            i=i-1;\n",
    "        jj=jj+1;\n",
    "        # sprime = random.randint(0,H-1);\n",
    "        if jj==D-1:\n",
    "            next_st_int = '000';\n",
    "        else:\n",
    "            next_st_int = str(M[i+1,jj+1])+ str(M[i,jj+1]) + str(M[i-1,jj+1]);\n",
    "        sprime = dict_o[next_st_int];\n",
    "        Q[st,ac] = (1-alpha)*Q[st,ac] + alpha*(R[st,ac] + gamma*max(Q[sprime,:]));\n",
    "        # st = sprime;\n",
    "    iter=iter+1;\n",
    "    deltaQ = np.abs(Q-Q_prev);\n",
    "    deltaQ_norm = np.mean(deltaQ);\n",
    "    # print(\"dQ = \", deltaQ_norm)\n",
    "    Q_prev = Q*1.0;\n",
    "\n",
    "Q_obstacle = Q;\n",
    "\n",
    "# ipdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***************Litter module****************************\n",
    "\n",
    "H=8; L=3;\n",
    "# litter_penalty = -100;\n",
    "litter_reward = 100.;\n",
    "R = np.zeros((H,L));\n",
    "Q = np.random.rand(H,L)*1e-3;\n",
    "#R = np.zeros((16,3))\n",
    "#R states are 000, 001, 010, 011, 111, 110, 101, 100; 1=litter, 0=no litter\n",
    "#R actions are move NE, move E, move SE\n",
    "R[0,1] = 40.;#reward for just moving forward\n",
    "R[1,2] = litter_reward;\n",
    "R[2,1] = litter_reward;\n",
    "R[3,1:] = litter_reward;\n",
    "R[4,:] = litter_reward;\n",
    "R[5,:2] = litter_reward;\n",
    "R[6,[0,2]] = litter_reward;\n",
    "R[7,0] = litter_reward;\n",
    "epsilon = 0.1;\n",
    "alpha = 0.4;\n",
    "gamma = 0.5;\n",
    "\n",
    "# ipdb.set_trace()\n",
    "\n",
    "\n",
    "deltaQ_norm = 1;\n",
    "Q_prev = Q*1.0;\n",
    "st = random.randint(0,H-1);\n",
    "iter=0;\n",
    "tol=1e-3;\n",
    "iter_min=100;\n",
    "iter_max = 1000;\n",
    "# while deltaQ_norm>tol:\n",
    "dict_l = {'000':0, '001':1, '010':2, '011':3, '111':4, '110':5, '101':6, '100':7}\n",
    "\n",
    "while iter<iter_max:\n",
    "    start = random.randint(2,4)\n",
    "    jj=0;\n",
    "    i=start;\n",
    "    M = np.random.randint(6, size=(W, D))\n",
    "    M[M!=1]=0;\n",
    "    if deltaQ_norm<tol and iter>iter_min:\n",
    "        break\n",
    "    while jj<D-1:\n",
    "        st_int = str(M[i+1,jj+1])+ str(M[i,jj+1]) + str(M[i-1,jj+1]);\n",
    "        # st_int = str(O[i+1,jj])+ str(O[i,jj+1]) + str(O[i-1,jj]);\n",
    "        st = dict_l[st_int];\n",
    "        val_act_picked=0;\n",
    "        if deltaQ_norm<tol and iter>iter_min:\n",
    "            break\n",
    "        # ipdb.set_trace()\n",
    "        while val_act_picked!=1:\n",
    "            if np.random.rand()<epsilon:\n",
    "                ac = random.randint(0,L-1);\n",
    "            else:\n",
    "                ac = np.argmax(Q[st,:]);\n",
    "            if (i==W-2 and ac==0) or (i==1 and ac==2):\n",
    "                val_act_picked=0;\n",
    "            else:\n",
    "                val_act_picked=1;\n",
    "\n",
    "        if ac==0:\n",
    "            i=i+1;\n",
    "        elif ac==2:\n",
    "            i=i-1;\n",
    "        # else:\n",
    "            # jj=jj+1;\n",
    "        jj=jj+1;\n",
    "        if jj==D-1:\n",
    "            next_st_int = '000';\n",
    "            # next_st_int = str(O[i+1,jj])+ '0' + str(O[i-1,jj]);\n",
    "        else:\n",
    "            next_st_int = str(M[i+1,jj+1])+ str(M[i,jj+1]) + str(M[i-1,jj+1]);\n",
    "            # next_st_int = str(O[i+1,jj])+ str(O[i,jj+1]) + str(O[i-1,jj]);\n",
    "        sprime = dict_l[next_st_int];\n",
    "        Q[st,ac] = (1-alpha)*Q[st,ac] + alpha*(R[st,ac] + gamma*max(Q[sprime,:]));\n",
    "        if M[i,jj]==1:\n",
    "            M[i,jj]=0; #litter has been picked up\n",
    "        # st = sprime;\n",
    "    iter=iter+1;\n",
    "    deltaQ = np.abs(Q-Q_prev);\n",
    "    deltaQ_norm = np.mean(deltaQ);\n",
    "    # print(\"dQ = \", deltaQ_norm)\n",
    "    Q_prev = Q*1.0;\n",
    "\n",
    "Q_litter = Q;\n",
    "\n",
    "# ipdb.set_trace()\n",
    "\n",
    "#***********************Generating map and executing agent***************************\n",
    "H=7; L=25;\n",
    "W=7; D=25;\n",
    "M = np.zeros((H,L));\n",
    "\n",
    "\n",
    "M = np.random.randint(8, size=(W, D))\n",
    "M[M>2]=0;\n",
    "\n",
    "M_o = M*1;\n",
    "M_o[M_o==1]=0;\n",
    "M_o[M_o==2]=1;\n",
    "M_o[:,0]=0;#so that agent does not begin from an obstacle\n",
    "\n",
    "\n",
    "M_l = M*1;\n",
    "M_l[M_l==2]=0;\n",
    "\n",
    "M_s = M*0;\n",
    "M_s[2:5,:]=1;\n",
    "\n",
    "#***********************Normalizing Q matrices***********************\n",
    "# Q_swalk_rowsums = Q_swalk.sum(axis=1);\n",
    "# Q_swalk = Q_swalk/ Q_swalk_rowsums[:,np.newaxis];\n",
    "Q_swalk = normalize(Q_swalk, axis=1, norm='l1');\n",
    "Q_obstacle = normalize(Q_obstacle, axis=1, norm='l1');\n",
    "Q_litter = normalize(Q_litter, axis=1, norm='l1');\n",
    "\n",
    "start = random.randint(2,W-3);\n",
    "jj=0;\n",
    "i=start;\n",
    "agent_i = i;\n",
    "agent_j = jj;\n",
    "Q_ac = np.zeros(3);\n",
    "# ipdb.set_trace()\n",
    "w_s = 5; w_o=5; w_l=8;\n",
    "# w_s = 1; w_o=0; w_l=0;\n",
    "# w_s = 0; w_o=1; w_l=0;\n",
    "# w_s = 0; w_o=0; w_l=1;\n",
    "while jj<D-1:\n",
    "    st_ind_o = str(M_o[i+1,jj+1])+ str(M_o[i,jj+1]) + str(M_o[i-1,jj+1]);\n",
    "    st_o = dict_o[st_ind_o];\n",
    "\n",
    "    st_ind_l = str(M_l[i+1,jj+1])+ str(M_l[i,jj+1]) + str(M_l[i-1,jj+1]);\n",
    "    st_l = dict_l[st_ind_l];\n",
    "\n",
    "    st_ind_s = str(M_s[i+1,jj+1])+ str(M_s[i,jj+1]) + str(M_s[i-1,jj+1]);\n",
    "    st_s = dict_s[st_ind_s];\n",
    "\n",
    "    Q_ac[0] = w_s*Q_swalk[st_s,0] + w_o*Q_obstacle[st_o,0] + w_l*Q_litter[st_l,0];\n",
    "    Q_ac[1] = w_s*Q_swalk[st_s,1] + w_o*Q_obstacle[st_o,1] + w_l*Q_litter[st_l,1];\n",
    "    Q_ac[2] = w_s*Q_swalk[st_s,2] + w_o*Q_obstacle[st_o,2] + w_l*Q_litter[st_l,2];\n",
    "    print(i)\n",
    "    ac = np.argmax(Q_ac);\n",
    "    if ac==0 and i>=W-2:\n",
    "        ac=np.argmax(Q_ac[1:])+1\n",
    "    if ac==2 and i<=1:\n",
    "        ac=np.argmax(Q_ac[:2])\n",
    "\n",
    "    if ac==0:\n",
    "        i=i+1;\n",
    "    elif ac==2:\n",
    "        i=i-1;\n",
    "    jj=jj+1;\n",
    "\n",
    "\n",
    "    agent_i = np.vstack([agent_i,i]);\n",
    "    agent_j = np.vstack([agent_j,jj]);\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.spy(np.ones((W,D)), marker='o', markersize=6, color='k')\n",
    "plt.spy(M_s, marker='o', markersize=6, color='g')\n",
    "plt.spy(M_o, marker='x', markersize=10, color='r')\n",
    "plt.spy(M_l, marker='s', markersize=10, color='b')\n",
    "# plt.plot(agent_j, W-agent_i-1, '--k')\n",
    "plt.plot(agent_j, agent_i, '--k')\n",
    "plt.show()\n",
    "\n",
    "ipdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
